# 歌曲渲染

歌曲的渲染（包括调用歌声合成 API 等）通过 `RENDER` action 和其中调用的 `SongTrackRenderer.render()` 进行。

## `songTrackRendering.ts` 中主要类和类型的说明

### `SnapshotForRender`（快照）

这是项目（轨道信息、项目设置等）的快照。
为了防止在渲染处理过程中因原始数据被修改而导致不一致，它在渲染之前立即创建，并以该快照为基础进行渲染。

### `PhraseForRender`（乐句）

作为渲染的单位，它包含音符、相关信息以及通过渲染生成的中间和最终数据。
它被视为一个可变对象，其属性在渲染过程中会不断更新。
乐句通过用休止符分隔轨道上的音符来生成。

### `SongTrackRenderer`（歌曲轨道渲染器）

负责管理整个歌曲轨道渲染过程。

其主要功能如下：

-   **执行歌曲轨道渲染**
    将歌曲轨道上的音符分割成多个乐句，依次生成查询（音素时序）、歌唱音高和歌唱音量，然后合成最终的歌声。生成和合成以乐句为单位进行，优先处理靠近播放头的乐句。
-   **利用缓存**
    缓存生成的查询、音高、音量和歌声，以加快重新渲染时的处理速度。
-   **外部引擎集成**
    与歌声合成引擎集成，进行查询获取和歌声合成等操作。
-   **事件通知**
    在渲染的各个阶段（乐句生成、缓存应用、歌声数据生成完成、错误发生等）发出事件，通知外部组件。
-   **中断处理**
    提供从外部中断正在进行的渲染处理的功能。

## 歌曲渲染流程

当 `SingingStore` 的 `RENDER` action 被调用时，将执行以下处理（[流程图](res/ソングのレンダリングのフローチャート.md)）：

1.  检查 `songTrackRenderer` 实例是否存在。
    -   如果不存在，则调用 `SETUP_SONG_TRACK_RENDERER` action 来生成实例并注册事件监听器。
2.  检查渲染循环是否正在运行。
    -   如果正在运行，则请求重新渲染（中断正在进行的渲染并重新启动渲染），然后结束 `RENDER` action。
    -   如果未运行，则请求开始渲染并继续处理。
3.  **执行渲染循环**
    只要存在渲染开始（或重新启动）请求，并且没有渲染停止请求，就重复以下处理：
    1.  **创建项目快照 (`createSnapshot`)**
        创建可能在渲染处理中被修改的数据（项目）的副本（快照）。
    2.  **生成乐句 (`generatePhrases`)**
        基于快照中的音符信息，生成作为渲染基本单位的乐句（`PhraseForRender`）。乐句通过用休止符分隔音符来生成。
        此时，乐句尚未包含音频数据或其基础的详细参数。
        完成后，将发出 `PhrasesGeneratedEvent` 事件。
    3.  **提取可渲染的乐句 (`filterRenderablePhrases`)**
        从所有生成的乐句中，提取实际可渲染的乐句（例如：属于已分配歌手的轨道的乐句）。
    4.  **应用缓存数据 (`applyCachedDataToPhrases`)**
        对于每个可渲染的乐句，检查缓存中是否存在过去的渲染结果（查询、歌唱音高、歌唱音量、歌声），如果存在，则加载并应用于乐句。
        具体来说，对每个乐句执行以下处理：
        1.  **应用查询缓存**
            -   如果查询缓存存在，则加载并应用于乐句。
            -   如果查询缓存不存在，则进入下一个乐句的缓存加载处理。
        2.  **应用歌唱音高缓存**
            -   如果歌唱音高缓存存在，则加载并应用于乐句。
            -   如果歌唱音高缓存不存在，则进入下一个乐句的缓存加载处理。
        3.  **应用歌唱音量缓存**
            -   如果歌唱音量缓存存在，则加载并应用于乐句。
            -   如果歌唱音量缓存不存在，则进入下一个乐句的缓存加载处理。
        4.  **应用歌声缓存**
            -   如果歌声缓存存在，则加载并应用于乐句。

        完成后，将发出 `CacheLoadedEvent`。
    5.  **提取需要渲染的乐句 (`filterPhrasesRequiringRender`)**
        即使应用了缓存，仍然缺少查询、歌唱音高、歌唱音量或歌声的乐句，才是实际需要渲染的乐句。将它们提取出来。
    6.  **渲染每个乐句**
        只要存在未处理（未渲染）的乐句，并且没有中断请求，就重复以下处理：
        1.  **选择要渲染的乐句 (`selectPriorPhrase`)**
            从等待渲染的乐句组中，选择离当前播放头位置最近的乐句作为下一个处理对象。
        2.  **渲染乐句 (`renderPhrase`)**
            对选定的乐句，依次执行以下处理：
            1.  发出 `PhraseRenderingStartedEvent`。
            2.  **生成查询（音素时序）**
                1.  如果查询尚未生成，则调用引擎 API (`engineSongApi.fetchFrameAudioQuery`) 生成查询。
                2.  生成后，将结果保存到缓存并应用于乐句。
                3.  发出 `QueryGenerationCompleteEvent`。
            3.  **生成歌唱音高**
                1.  如果歌唱音高尚未生成，则调用引擎 API (`engineSongApi.fetchSingFrameF0`) 生成歌唱音高。
                2.  生成后，将结果保存到缓存并应用于乐句。
                3.  发出 `PitchGenerationCompleteEvent`。
            4.  **生成歌唱音量**
                1.  如果歌唱音量尚未生成，则调用引擎 API (`engineSongApi.fetchSingFrameVolume`) 生成歌唱音量。
                2.  生成后，将结果保存到缓存并应用于乐句。
                3.  发出 `VolumeGenerationCompleteEvent`。
            5.  **合成歌声**
                1.  如果歌声尚未生成，则调用引擎 API (`engineSongApi.frameSynthesis`) 合成歌声。
                2.  生成后，将结果保存到缓存并应用于乐句。
                3.  发出 `VoiceSynthesisCompleteEvent`。
            6.  乐句渲染完成后，发出 `PhraseRenderingCompleteEvent`。
                如果在乐句渲染过程中发生错误，则发出 `PhraseRenderingErrorEvent`，并继续处理下一个乐句。
